# Dream-scrapper

# ğŸ§  Dramed Scrapper â€” Agent Web Intelligent

Dramed Scrapper est un **agent web intelligent** qui visite des sites web, comprend leur contenu et en extrait automatiquement des informations utiles (nom dâ€™Ã©cole, contacts, programmes, etc.) sous forme de **fiche structurÃ©e**.

---

## ğŸš€ TL;DR

- ğŸ§­ Va automatiquement sur les sites (navigation headless avec Playwright)  
- ğŸ‘ï¸ Comprend la page avec un LLM (type GPT)  
- ğŸ§¾ Extrait les infos utiles (mails, adresses, programmes, etc.)  
- ğŸ“‡ GÃ©nÃ¨re une **fiche synthÃ¨se** standardisÃ©e (ex : Ã©cole / organisation)  
- ğŸŒ Expose tout Ã§a via une **API FastAPI** (`/scrape` et `/results/{id}`)

---

## ğŸ¯ Objectif du projet

Automatiser la recherche dâ€™informations sur des Ã©coles, organisations ou programmes :

- Qui ? â†’ Nom, type, pays, ville  
- OÃ¹ ? â†’ Site web, adresses  
- Comment contacter ? â†’ Emails, tÃ©lÃ©phones, pages de contact  
- Que fait lâ€™Ã©cole ? â†’ Description, domaines  
- Quels programmes ? â†’ Programmes principaux, domaines dâ€™enseignement  
- Comment candidater ? â†’ Liens et rÃ©sumÃ© des conditions si dÃ©tectÃ©s  

---

## ğŸ§© Fonctionnement global

1. **Navigation** : un navigateur headless ouvre lâ€™URL, clique sur les liens, scrolle, gÃ¨re la pagination.
2. **Perception** : un LLM analyse le HTML et dÃ©tecte le type de page + zones importantes.
3. **Extraction** : le LLM extrait les donnÃ©es demandÃ©es selon des instructions (nom, emails, etc.).
4. **SynthÃ¨se** : les donnÃ©es sont transformÃ©es en **fiche profil** (ex : profil dâ€™Ã©cole).
5. **Validation** : vÃ©rification de la cohÃ©rence (structure, champs essentiels).
6. **Stockage / API** : les rÃ©sultats sont sauvegardÃ©s et accessibles via lâ€™API.

---

## ğŸ§± Architecture (modules)

Le projet est organisÃ© en plusieurs modules indÃ©pendants :

- `navigator.py` : navigation web (Playwright)
- `perception_agent.py` : analyse de page (LLM)
- `extractor.py` : extraction des donnÃ©es ciblÃ©es
- `strategy_agent.py` : agent stratÃ©gique (exploration multi-pages)
- `profile_synthesis.py` : gÃ©nÃ©ration de la fiche synthÃ¨se (profil Ã©cole / organisation)
- `validation.py` : vÃ©rification des rÃ©sultats
- `storage.py` : sauvegarde en JSON/CSV
- `server.py` : API FastAPI

---

## ğŸ› ï¸ Stack technique

- **Langage** : Python 3.11
- **Backend / API** : FastAPI + Uvicorn
- **Navigation web** : Playwright (mode headless)
- **LLM** : modÃ¨le accessible via API (OpenAI ou Ã©quivalent)
- **Stockage** : fichiers JSON (MVP), extension possible en PostgreSQL/MongoDB

---

## ğŸ“ Structure du projet

```bash
dramed_scrapper/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ navigator.py
â”‚   â”œâ”€â”€ perception_agent.py
â”‚   â”œâ”€â”€ extractor.py
â”‚   â”œâ”€â”€ strategy_agent.py
â”‚   â”œâ”€â”€ profile_synthesis.py
â”‚   â”œâ”€â”€ validation.py
â”‚   â”œâ”€â”€ storage.py
â”‚   â””â”€â”€ server.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_navigator.py
â”‚   â”œâ”€â”€ test_perception.py
â”‚   â”œâ”€â”€ test_extractor.py
â”‚   â””â”€â”€ test_end_to_end.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_local_scrape.py
â”‚   â””â”€â”€ demo_notebook.ipynb   # (optionnel)
â”œâ”€â”€ data/                     # rÃ©sultats des runs (crÃ©Ã© Ã  lâ€™exÃ©cution)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env.example
